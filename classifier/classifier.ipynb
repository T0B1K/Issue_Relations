{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "CowV6N_J5NPu",
        "outputId": "a75da3dc-c470-4016-b86b-c2e020771fe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/trainingsdata.zip"
      ],
      "metadata": {
        "id": "7hMqvqvO5V7t",
        "outputId": "9441b619-c617-4d56-a517-6528aeb7625b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/trainingsdata.zip\n",
            "  inflating: y_train.npy             \n",
            "  inflating: y_val.npy               \n",
            "  inflating: X_test.csv              \n",
            "  inflating: X_train.csv             \n",
            "  inflating: X_val.csv               \n",
            "  inflating: y_test.npy              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7sQLhr4vfzq",
        "outputId": "9445e0b8-e67b-4ec0-eb95-708d7fd184fb"
      },
      "source": [
        "!unzip trainingsdata.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  trainingsdata.zip\n",
            "  inflating: y_train.npy             \n",
            "  inflating: y_val.npy               \n",
            "  inflating: X_test.csv              \n",
            "  inflating: X_train.csv             \n",
            "  inflating: X_val.csv               \n",
            "  inflating: y_test.npy              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81yczvs7crZC",
        "outputId": "be4bd3f7-5f9c-4fd5-f698-6d52c34709f4"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: lda_train.npy           \n",
            "  inflating: lda_val.npy             \n",
            "  inflating: X_test_ft_avg.npy       \n",
            "  inflating: X_test_ft_usif.npy      \n",
            "  inflating: X_test_glove_avg.npy    \n",
            "  inflating: X_test_glove_usif.npy   \n",
            "  inflating: X_train_ft_avg.npy      \n",
            "  inflating: X_train_ft_usif.npy     \n",
            "  inflating: X_train_glove_avg.npy   \n",
            "  inflating: X_train_glove_usif.npy  \n",
            "  inflating: X_val_ft_avg.npy        \n",
            "  inflating: X_val_ft_usif.npy       \n",
            "  inflating: X_val_glove_avg.npy     \n",
            "  inflating: X_val_glove_usif.npy    \n",
            "  inflating: lda_test.npy            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTTjE0vnQ3Sc"
      },
      "source": [
        "# Imports\n",
        "Here the imports are listed, which are important for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-01uSWN0NBt",
        "outputId": "89458eea-35d3-4e17-b9da-f452bfb5d4e8"
      },
      "source": [
        "!pip install gensim\n",
        "!pip install -U git+https://github.com/oborchers/Fast_Sentence_Embeddings"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Collecting git+https://github.com/oborchers/Fast_Sentence_Embeddings\n",
            "  Cloning https://github.com/oborchers/Fast_Sentence_Embeddings to /tmp/pip-req-build-07budv97\n",
            "  Running command git clone -q https://github.com/oborchers/Fast_Sentence_Embeddings /tmp/pip-req-build-07budv97\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from fse==1.0.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from fse==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: smart_open>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from fse==1.0.0) (6.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from fse==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: gensim>=4 in /usr/local/lib/python3.7/dist-packages (from fse==1.0.0) (4.2.0)\n",
            "Requirement already satisfied: wordfreq>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from fse==1.0.0) (3.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from fse==1.0.0) (0.5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from fse==1.0.0) (5.4.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->fse==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->fse==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq>=2.2.1->fse==1.0.0) (1.0.3)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq>=2.2.1->fse==1.0.0) (3.3.0)\n",
            "Requirement already satisfied: regex>=2020.04.04 in /usr/local/lib/python3.7/dist-packages (from wordfreq>=2.2.1->fse==1.0.0) (2022.4.24)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.7/dist-packages (from wordfreq>=2.2.1->fse==1.0.0) (6.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy>=6.1->wordfreq>=2.2.1->fse==1.0.0) (0.2.5)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse==1.0.0) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse==1.0.0) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse==1.0.0) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse==1.0.0) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse==1.0.0) (4.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse==1.0.0) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->fse==1.0.0) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->fse==1.0.0) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->fse==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->fse==1.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->fse==1.0.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->fse==1.0.0) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hIqHHCvjnP"
      },
      "source": [
        "import numpy\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "#from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow import keras\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "#logger\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "#type annotation\n",
        "from typing import *\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "import gc\n",
        "gc.enable()\n",
        "\n",
        "SEED = 100    #reproduceability\n",
        "from tensorflow.keras.layers import Embedding"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSkxgNztW6oa"
      },
      "source": [
        "## Vectorisation (if needed)\n",
        "If already vectorised documents are used, this step can be ignored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diIlmixUX0CT"
      },
      "source": [
        "### Bow vectoriser and Sentence encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_po6xl-85bV"
      },
      "source": [
        "def getVectoriser(kind:str = \"tfIdf\", vocab=512, ngram_range=(1,1), trainingsData=None):\n",
        "  \"\"\"This function creates the vectoriser according to the parameter and returns it.\n",
        "      It can be either a count, tfIdf or sentence vectoriser.\n",
        "\n",
        "    Args:\n",
        "        kind (str): The kind of the vectoriser such as 'tfIdf', 'sentence' or 'count'\n",
        "        vocab (number): The length of the vocabulary\n",
        "        ngram_range (any): The ngram range\n",
        "        trainingsData (any): The trainingsdata\n",
        "\n",
        "    Returns:\n",
        "        The vectoriser object\n",
        "    \"\"\"\n",
        "  global vectoriser_func\n",
        "  if kind is \"tfIdf\":\n",
        "    vectoriser = TfidfVectorizer(lowercase=True, min_df=2, max_features=vocab, ngram_range=ngram_range, stop_words=\"english\")\n",
        "    trainVectoriser(vectoriser, trainingsData)\n",
        "    return vectoriser\n",
        "  elif kind is \"count\":\n",
        "    vectoriser = CountVectorizer(lowercase=True, min_df=2, max_features=vocab, ngram_range=ngram_range, stop_words=\"english\")\n",
        "    trainVectoriser(vectoriser, trainingsData)\n",
        "    return vectoriser\n",
        "  elif kind is \"sentence\":\n",
        "    return hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "\n",
        "def trainVectoriser(vectoriser, trainingsData):\n",
        "  \"\"\"This function is used to train the vectoriser\n",
        "\n",
        "    Args:\n",
        "        trainingsData (any): The data used for training\n",
        "        vectoriser (any): The vectoriser itself\n",
        "\n",
        "    Returns:\n",
        "        The vectorised data.\n",
        "    \"\"\"\n",
        "  \n",
        "  text_ds = trainingsData.flatten()\n",
        "  tmp = vectoriser.fit_transform(text_ds)\n",
        "  logger.info(tmp.shape)\n",
        "  del text_ds, tmp\n",
        "  gc.collect()\n",
        "\n",
        "def batchVectorisation(dfData, vectoriser, kindOfvectoriser:str):\n",
        "  \"\"\"This function loads the data in batches to reduce RAM requirenments.\n",
        "    Also it dstinguishes between 'sentence' for the sentence encoder and plain sklearn\n",
        "    vectorisers\n",
        "\n",
        "    Args:\n",
        "        dfData (any): The data of the dataframe\n",
        "        vectoriser (any): The vectoriser itself\n",
        "        kindOfvectoriser (str): This is the 'name' of the vectoriser, such as tfidf\n",
        "\n",
        "    Returns:\n",
        "        The vectorised data.\n",
        "    \"\"\"\n",
        "  \n",
        "  if kindOfvectoriser is \"sentence\":\n",
        "    vecFunc = lambda string: vectoriser(tf.constant(string)) \n",
        "  else:\n",
        "    vecFunc = lambda string: vectoriser.transform(string).toarray()\n",
        "  l = dfData[:,0]\n",
        "  r = dfData[:,1]\n",
        "  returnValue = [[],[]]\n",
        "  batch_size = 250\n",
        "  while len(l) >0 :\n",
        "    le = vecFunc(l[:batch_size]) #vectoriser.transform(l[:batch_size]).toarray()\n",
        "    re = vecFunc(r[:batch_size]) #vectoriser.transform(r[:batch_size]).toarray()\n",
        "\n",
        "    if len(returnValue[0]) == 0:\n",
        "      returnValue[0] = le\n",
        "      returnValue[1] = re\n",
        "    else:\n",
        "      returnValue[0] = numpy.concatenate((returnValue[0], le), axis=0)\n",
        "      returnValue[1] = numpy.concatenate((returnValue[1], re), axis=0)\n",
        "\n",
        "    l = l[batch_size:]\n",
        "    r = r[batch_size:]\n",
        "    logger.info(f\"{returnValue[0].shape} todo {l.shape}\")\n",
        "  return returnValue\n",
        "\n",
        "def vectoriseData(vectoriser, training, validation, kind:str = \"tfidf\"):\n",
        "  \"\"\"This function vectorises the data provided given the vectoriser provided.\n",
        "\n",
        "    Args:\n",
        "        vectoriser (any): This is the vectoriser object, it can be either be the\n",
        "        universal setnence encoder or one of the bow vectorisers\n",
        "        training (any): Is the trainingsdata data\n",
        "        validation (any): Is the validation data\n",
        "        kind (str): Is the data proviced\n",
        "\n",
        "    Returns:\n",
        "        The list of tokenised documents\n",
        "    \"\"\"\n",
        "  X_train_list = batchVectorisation(training, vectoriser, kind)\n",
        "  X_val_list = batchVectorisation(validation, vectoriser, kind)\n",
        "  return X_train_list, X_val_list"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCvW72CsYhFw"
      },
      "source": [
        "### GloVe; Fasttext usif and avg document embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3II5IBo7_4r",
        "outputId": "fcd85c2c-2b4b-4fc6-a719-3deecb2ba120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from gensim.models import Word2Vec, FastText\n",
        "!pip install -U fse\n",
        "from fse.models.average import FAST_VERSION\n",
        "print(FAST_VERSION) #1 means available\n",
        "from fse.models import Average, uSIF\n",
        "import gensim.downloader as api\n",
        "from fse import IndexedList\n",
        "\n",
        "class EmbeddingModels():\n",
        "  \"\"\"This class is used to create a Embedding model, which is able to vectorise documents.\n",
        "    Returns:\n",
        "        The document embeddings producing object\n",
        "    \"\"\"\n",
        "  def __init__(self, vocab_len, trainingsdata, embedName, combiName):\n",
        "    self.tokenizer = TfidfVectorizer(lowercase=True, min_df=2, max_features=vocab_len, ngram_range=(1,1), stop_words=\"english\").build_tokenizer()\n",
        "    tokdata = self.tokenize(trainingsdata)\n",
        "\n",
        "    self.embed = self.get_embedding(tokdata, embedName, vocab_len)\n",
        "    logger.error(\"got embedding\")\n",
        "\n",
        "    tokdata = IndexedList(tokdata)\n",
        "    logger.error(\"csp\")\n",
        "\n",
        "    self.model = self.getMergingMethod(combiName, self.embed, embedName, vocab_len)\n",
        "    logger.error(\"got combi\")\n",
        "    self.model.train(tokdata)\n",
        "    logger.error(\"finished training\")\n",
        "  \n",
        "  def getMergingMethod(self, combiName:str, embedding, embedName:str, voc_len):\n",
        "    \"\"\"This function returns the merging method for the word embeddings.\n",
        "\n",
        "    Args:\n",
        "        embedding (any): Serves the word embeddings\n",
        "        embedName (str): is the name of the embeddings\n",
        "        voc_len (number): is the lenght of the vocabulary\n",
        "        combiName (str): embedName is the name of the embeddings\n",
        "\n",
        "    Returns:\n",
        "        The Merging method\n",
        "    \"\"\"\n",
        "    if combiName is \"avg\":\n",
        "      return Average(embedding)\n",
        "    else:\n",
        "      if embedName is \"glove\":\n",
        "        return uSIF(embedding, workers=2, lang_freq=\"en\")\n",
        "      else:\n",
        "        return uSIF(embedding, length=voc_len)\n",
        "\n",
        "  def get_embedding(self, trainingsdata, embedName:str, vocab_len):\n",
        "    \"\"\"This function creates and returns an embedding for the given trainingsdata.\n",
        "\n",
        "    Args:\n",
        "        trainingsdata (List[str]): Is the data proviced\n",
        "        embedding (any): Serves the word embeddings\n",
        "        embedName (str): is the name of the embeddings\n",
        "        vocab_len (number): is the lenght of the vocabulary\n",
        "        combiName (str): embedName is the name of the embeddings\n",
        "\n",
        "    Returns:\n",
        "        The word level embedding function \n",
        "    \"\"\"\n",
        "    if embedName is \"glove\":\n",
        "      return api.load(\"glove-wiki-gigaword-100\")\n",
        "    elif embedName is \"fasttext\":\n",
        "      return FastText(window=3, min_count=1, sentences=trainingsdata, size=vocab_len)\n",
        "    else:\n",
        "      return Word2Vec(trainingsdata, min_count=1, size=vocab_len)\n",
        "\n",
        "  def tokenize(self, data)->list:\n",
        "    \"\"\"This function tokenises all the documents in the data.\n",
        "\n",
        "    Args:\n",
        "        data (any): Is the data proviced\n",
        "\n",
        "    Returns:\n",
        "        The list of tokenised documents\n",
        "    \"\"\"\n",
        "    return [self.tokenizer(doc) for doc in data]\n",
        "\n",
        "  def predict(self, data)->list:\n",
        "    \"\"\"This function creates the document embeddings\n",
        "\n",
        "    Args:\n",
        "        data (any): Is the data proviced\n",
        "\n",
        "    Returns:\n",
        "        The document embeddings\n",
        "    \"\"\"\n",
        "    tokenized_data = self.tokenize(data)\n",
        "    idxTok = IndexedList(tokenized_data)\n",
        "    inf_tokens = list(map(lambda tokenList: (tokenList, 0), tokenized_data))\n",
        "    #print(numpy.array(inf_tokens))\n",
        "    return list(map(lambda inf_data: self.model.infer([inf_data])[0], inf_tokens))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fse in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: gensim>=4 in /usr/local/lib/python3.7/dist-packages (from fse) (4.2.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from fse) (5.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from fse) (1.0.2)\n",
            "Requirement already satisfied: wordfreq>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from fse) (3.0.1)\n",
            "Requirement already satisfied: smart-open>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from fse) (6.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from fse) (1.4.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from fse) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from fse) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->fse) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->fse) (3.1.0)\n",
            "Requirement already satisfied: regex>=2020.04.04 in /usr/local/lib/python3.7/dist-packages (from wordfreq>=2.2.1->fse) (2022.4.24)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq>=2.2.1->fse) (3.3.0)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.7/dist-packages (from wordfreq>=2.2.1->fse) (6.1.1)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq>=2.2.1->fse) (1.0.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy>=6.1->wordfreq>=2.2.1->fse) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse) (4.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->fse) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->fse) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->fse) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->fse) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->fse) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->fse) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->fse) (3.0.4)\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmbR-ITkAajd"
      },
      "source": [
        "## LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCet23LLr_pp"
      },
      "source": [
        "class NumberNormalizingVectorizer(TfidfVectorizer):\n",
        "  \"\"\"This class creates a custom vectoriser used for the LDA.\n",
        "\n",
        "    Returns:\n",
        "        A object of the Vectoriser\n",
        "    \"\"\"\n",
        "  def build_tokenizer(self):\n",
        "    tokenize = super().build_tokenizer()\n",
        "    return lambda doc: list(self.number_normalizer(tokenize(doc)))\n",
        "\n",
        "  def number_normalizer(self, tokens):\n",
        "    return (\"NUMBER\" if token[0].isdigit() else token for token in tokens)\n",
        "\n",
        "class GenerateLdaTopics():\n",
        "  \"\"\"\n",
        "  This Class is used to generate the LDA\n",
        "  \"\"\"\n",
        "  def __init__(self, _n_topics=200):\n",
        "    self.n_topics = _n_topics\n",
        "    self.cv = NumberNormalizingVectorizer(lowercase=True, min_df=5, max_features=20000, max_df=0.5, stop_words=\"english\",token_pattern='[a-zA-Z]+')\n",
        "    self.lda = LatentDirichletAllocation(n_components=_n_topics, random_state=0,n_jobs=-1)\n",
        "    self.vocab = None\n",
        "    \n",
        "  def fit(self, data):\n",
        "    \"\"\"This function is used to fit the LDA model.\n",
        "\n",
        "    Args:\n",
        "        data (any): The data passed to the vectoriser\n",
        "    \"\"\"\n",
        "    vectorised_data = self.cv.fit_transform(X_train.flatten())\n",
        "    logger.info(\"data vectorised\")\n",
        "    self.vocab = self.cv.get_feature_names()\n",
        "    logger.info(\"fitting lda\")\n",
        "    self.lda.fit(vectorised_data)\n",
        "\n",
        "  def predict(self, data):\n",
        "    \"\"\"This function returns the topic propabilities for the documents.\n",
        "\n",
        "    Args:\n",
        "        data (any): The data to produce the document-topic matri from\n",
        "\n",
        "    Returns:\n",
        "        The document-topic matrix\n",
        "    \"\"\"\n",
        "    vec_data = self.cv.transform(data)     #document-term matrix\n",
        "    return self.lda.transform(vec_data)    #document-topic matrix\n",
        "\n",
        "  def print_topics(self,n_top_words=5):\n",
        "    \"\"\"In order to visualise the topics,\n",
        "    this document prints representatives of the topics to show which words are contained within each topic.\n",
        "\n",
        "    Args:\n",
        "        n_top_words (number): The number words displayed for the topics\n",
        "\n",
        "    Returns:\n",
        "        A trainable model\n",
        "    \"\"\"\n",
        "    for topic, comp in enumerate(self.lda.components_):  #iterate through the topic-term matrix\n",
        "      word_idx = numpy.argsort(comp)[:-n_top_words-1:-1]\n",
        "      words = [self.vocab[i] for i in word_idx]\n",
        "      print('Topic: %d' % topic)\n",
        "      print('  %s' % ', '.join(words)) \n",
        "\n",
        "  def print_predictedTopics(self, data, n_top_topics = 5):\n",
        "    \"\"\"This function appends the vector length onto the vector itself.\n",
        "\n",
        "    Args:\n",
        "        data (number): The length of the documents\n",
        "        n_top_topics (number): The number of topics\n",
        "\n",
        "    Returns:\n",
        "        A trainable model\n",
        "    \"\"\"\n",
        "    pred = self.predict(data)\n",
        "    topicsAndPropabilities = []\n",
        "    for p in pred:    #for document in document-topic\n",
        "      top_topics = p.argsort()[:-n_top_topics - 1:-1]\n",
        "      propabilities = p[top_topics]\n",
        "      topicsAndPropabilities.append([top_topics, propabilities])#print k best topics\n",
        "    return topicsAndPropabilities"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROtdSDkp_rjy"
      },
      "source": [
        "#The classifier\n",
        "To change the classifier, the concatenation layer in the *createModel* function has to be edited.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUNZCa7aeZgp"
      },
      "source": [
        "class LayerAppendSum(tf.keras.layers.Layer):\n",
        "  \"\"\"This function appends the vector length onto the vector itself.\n",
        "    \"\"\"\n",
        "  def __init__(self):\n",
        "      super(LayerAppendSum, self).__init__()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"\"\"This function gets automatically called with the data.\n",
        "\n",
        "    Args:\n",
        "        inputs (any): A vector within a vector of all the batches\n",
        "\n",
        "    Returns:\n",
        "        A concatenated vector length onto the vector \n",
        "    \"\"\"\n",
        "    def mapfunc(vec):\n",
        "      reduced_sum = tf.reduce_sum(vec)\n",
        "      reshaped = tf.reshape(reduced_sum, [-1])\n",
        "      return tf.concat([vec, reshaped], 0)\n",
        "    return tf.map_fn(lambda batch: mapfunc(batch), inputs)  #tf.concat([inputs, reduced])\n",
        "\n",
        "\n",
        "def createModel(vec_len:int):\n",
        "  \"\"\"This function creates a classifier for feature lists of the vec_len provided\n",
        "\n",
        "    Args:\n",
        "        vec_len (int): The length of the documents\n",
        "\n",
        "    Returns:\n",
        "        A trainable model\n",
        "    \"\"\"\n",
        "  ain = keras.Input(shape=(vec_len,), dtype=\"float\")\n",
        "  bin = keras.Input(shape=(vec_len,), dtype=\"float\")\n",
        "\n",
        "  a = tf.keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=0))(ain)\n",
        "  b = tf.keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=0))(bin)\n",
        "\n",
        "  avg_layer = tf.keras.layers.Average(name=\"avg\")([a, b])\n",
        "  mult_layer = tf.keras.layers.Multiply(name=\"mult\")([a,b])\n",
        "  sub_layer = tf.keras.layers.Subtract(name=\"sub\")([a, b])\n",
        "\n",
        "  cosine_sim = tf.keras.layers.Dot(axes=1, normalize=True, name=\"cosine_similarity\")([a,b])\n",
        "  #topic_sim = tf.keras.layers.Dot(axes=1, normalize=True, name=\"topic_similarity\")([x,y])\n",
        "\n",
        "  #avg_layer = LayerAppendSum()(avg_layer)\n",
        "  #mult_layer = LayerAppendSum()(mult_layer)\n",
        "  #sub_layer = LayerAppendSum()(sub_layer)\n",
        "\n",
        "  hidden = tf.keras.layers.concatenate([sub_layer, avg_layer, mult_layer,cosine_sim])#a,b , topic_sim])\n",
        "\n",
        "  outputs = layers.Dense(5, activation='softmax')(hidden)\n",
        "\n",
        "  model = keras.Model([ain,bin], outputs)   #,x,y\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "  #model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy']),\n",
        "  return model\n",
        "\n",
        "def download_model(model):\n",
        "  \"\"\"\n",
        "  This function is used to download models from google collab specifficly.\n",
        "  !tar -czvf model.tar.gz model/ is used for tarring the model\n",
        "  !tar -xvzf model.tar.gz is used for ent-tarring the model\n",
        "  \"\"\"\n",
        "  model.save(f\"./tmp_model\")\n",
        "  !tar -czvf tmp_model.tar.gz tmp_model/\n",
        "  from google.colab import files\n",
        "  files.download('tmp_model.tar.gz')\n",
        "\n",
        "def eval_model(predLabel:List[int], true_label:List[int]):\n",
        "  \"\"\"This function is used to determine the precision, recall and f1 score of a given model.\n",
        "\n",
        "    Args:\n",
        "        predLabel (List[int]): The predicted label of the model\n",
        "        predLabel (List[int]): The gold standard label\n",
        "\n",
        "    Returns:\n",
        "        The precission, recall, f1, and f1_macro scores\n",
        "    \"\"\"\n",
        "  f1_scores = sklearn.metrics.f1_score(y_true=true_label, y_pred=predLabel, average=None)\n",
        "  precission = sklearn.metrics.precision_score(y_true=true_label, y_pred=predLabel, average=None)\n",
        "  recall = sklearn.metrics.recall_score(y_true=true_label, y_pred=predLabel, average=None)\n",
        "\n",
        "  precission = list(map(lambda x: round(x, 4), precission))\n",
        "  recall = list(map(lambda x: round(x, 4), recall))\n",
        "  f1 = list(map(lambda x: round(x, 4), f1_scores))\n",
        "  f1_macro =  round(sum(f1)/len(f1), 4)\n",
        "  return precission, recall, f1, f1_macro"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkLfsjhm812c"
      },
      "source": [
        "## Running the model configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uq6b-CVsB_e"
      },
      "source": [
        "#newLda = GenerateLdaTopics()\n",
        "#newLda.fit(X_train.flatten())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enktq0-k6oqd"
      },
      "source": [
        "#### Finding the best vectoriser configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBxwsBFx68UB"
      },
      "source": [
        "def loadTrainAndValFeatures(nameTrainDataset: str, nameValDataset: str) -> list:\n",
        "  \"\"\"This function loads the training and validation data.\n",
        "\n",
        "    Args:\n",
        "        nameTrainDataset (str): The name of the training dataset\n",
        "        nameValDataset (str): The name of the validation dataset\n",
        "\n",
        "    Returns:\n",
        "        Both, the training and validation dataset\n",
        "    \"\"\"\n",
        "  X_train:numpy.ndarray = loadCSVData(\"X_train\")\n",
        "  X_val:numpy.ndarray = loadCSVData(\"X_val\")\n",
        "\n",
        "  return X_train, X_val\n",
        "\n",
        "def loadCSVData(name:str) -> numpy.ndarray:\n",
        "  \"\"\"This function loads SCV give the name.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the dataset\n",
        "\n",
        "    Returns:\n",
        "        The numpy array\n",
        "    \"\"\"\n",
        "  return pd.read_csv(f\"{name}.csv\")[[\"IssueA\", \"IssueB\"]].values.astype(\"str\")\n",
        "\n",
        "def loadNpData(name:str)-> numpy.ndarray:\n",
        "  \"\"\"This function loads numpy data give the name.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the dataset\n",
        "\n",
        "    Returns:\n",
        "        The numpy array\n",
        "    \"\"\"\n",
        "  return numpy.load(name+\".npy\", allow_pickle=True)\n",
        "\n",
        "def loadTrainAndValResults(nameTrainDataset: str, nameValDataset: str):\n",
        "  \"\"\"This function loads the training and validation results.\n",
        "\n",
        "    Args:\n",
        "        nameTrainDataset (str): The name of the training dataset\n",
        "        nameValDataset (str): The name of the validation dataset\n",
        "\n",
        "    Returns:\n",
        "        Both, the training and validation results\n",
        "    \"\"\"\n",
        "  Y_train = loadNpData(\"y_train\")\n",
        "  Y_val = loadNpData(\"y_val\")\n",
        "  Y_val = numpy.array([numpy.array(x) for x in Y_val])\n",
        "  Y_train = numpy.array([numpy.array(x) for x in Y_train])\n",
        "  return Y_train, Y_val\n",
        "\n",
        "\n",
        "def getVectorisedDataFromDataset(lda:bool, name:str, lda_name:str = None):\n",
        "  \"\"\"This function loads a specific X_train and X_val dataset and appends lda if needed.\n",
        "\n",
        "    Args:\n",
        "        lda (bool): Whether or not the model uses lds.\n",
        "        name (str): The The name of the data to load.\n",
        "        lda_name (str): The name of the lda datato load.\n",
        "\n",
        "    Returns:\n",
        "        The loaded data\n",
        "    \"\"\"\n",
        "  tmp_list = list(loadNpData(name))\n",
        "\n",
        "  if lda:\n",
        "    lda_data = list(loadNpData(lda_name))\n",
        "    tmp_list.append(lda_data[0])\n",
        "    tmp_list.append(lda_data[1])\n",
        "\n",
        "  return tmp_list\n",
        "\n",
        "def createVectorisedData(name:str,ngram,voc:int, lda:bool, X_train, X_val):\n",
        "  \"\"\"This function creates vectorised data, by creating a vectoriser given the requirenments specified and transforms the data given.\n",
        "\n",
        "    Args:\n",
        "        lda (bool): Whether or not the model uses lds.\n",
        "        name (str): The name of the data to load.\n",
        "        voc (int): The length of the vocabulary.\n",
        "        ngram (tuple): The ngram itself.\n",
        "        X_train (any): The training data.\n",
        "        X_val (any): The validation data.\n",
        "\n",
        "    Returns:\n",
        "        The training and validation data\n",
        "    \"\"\"\n",
        "  newLda= None\n",
        "  vectoriser = getVectoriser(trainingsData=X_train, vocab=voc, kind=name, ngram_range=ngram)\n",
        "  X_train_list, X_val_list = vectoriseData(vectoriser, X_train, X_val, kind=name)\n",
        "  if lda:\n",
        "    newLda = GenerateLdaTopics()\n",
        "    newLda.fit(X_train.flatten())\n",
        "    tl = newLda.predict(X_train[:,0])\n",
        "    tr = newLda.predict(X_train[:,1])\n",
        "    vl = newLda.predict(X_val[:,0])\n",
        "    vr = newLda.predict(X_val[:,1])\n",
        "\n",
        "    X_train_list.append(tl)\n",
        "    X_train_list.append(tr)\n",
        "    X_val_list.append(vl)\n",
        "    X_val_list.append(vr)\n",
        "\n",
        "  return X_train_list, X_val_list\n",
        "  \n",
        "def createAndEvaluateModel(X_train_list:list, X_val_list:list, Y_train, Y_val, voc:int):\n",
        "  \"\"\"This function creates and evaluates a model.\n",
        "    Args:\n",
        "        X_train_list (list): The training data.\n",
        "        X_val_list (list): The validation data.\n",
        "        Y_train (numpy.ndarray): The training solution.\n",
        "        Y_val (numpy.ndarray): The validation solution.\n",
        "        voc (int): The vocabulary size.\n",
        "\n",
        "    Returns:\n",
        "        The f1 scores evaluated\n",
        "    \"\"\"\n",
        "  model = createModel(voc)\n",
        "  model.fit(x=X_train_list, y=Y_train, batch_size = 25, epochs=25, validation_data=(X_val_list, Y_val))\n",
        "  output = model.predict(X_val_list, batch_size=15)\n",
        "  output = list(map(numpy.argmax, output))\n",
        "  y_val_int = list(map(numpy.argmax, Y_val))\n",
        "\n",
        "  return eval_model(output, y_val_int)\n",
        "\n",
        "\n",
        "def trainAndEvaluateModel(vectorisedData:bool, config, lda:bool):\n",
        "  \"\"\"\n",
        "  This function creates and evaluates multiple models.\n",
        "\n",
        "    Args:\n",
        "        vectorisedData (bool): The training data.\n",
        "        config (str): The validation data.\n",
        "        lda (bool): Whether or not LDA was used.\n",
        "\n",
        "    Returns:\n",
        "        The best vectoriser vonfiguration for the model\n",
        "    \"\"\"\n",
        "  precissions = []\n",
        "  recalls = []\n",
        "  f1s = []\n",
        "  f1_macros = []\n",
        "  Y_train, Y_val = loadTrainAndValResults(\"nameTrainDataset\", \"nameValDataset\")\n",
        "  \n",
        "  if vectorisedData:\n",
        "    for name in config:\n",
        "      X_train_list = getVectorisedDataFromDataset(lda, f\"X_train_{name}\")\n",
        "      X_val_list = getVectorisedDataFromDataset(lda, f\"X_val_{name}\")\n",
        "      voc = len(X_train_list[0][0])\n",
        "\n",
        "      precission, recall, f1, f1_macro = createAndEvaluateModel(X_train_list, X_val_list, Y_train, Y_val, voc)\n",
        "      precissions.append(precission)\n",
        "      recalls.append(recall)\n",
        "      f1s.append(f1)\n",
        "      f1_macros.append(f1_macro)\n",
        "      gc.collect()\n",
        "\n",
        "  else:\n",
        "    for name,ngram,voc in config:\n",
        "      X_train, X_val = loadTrainAndValFeatures(\"nameTrainDataset\", \"nameValDataset\")\n",
        "      X_train_list, X_val_list = createVectorisedData(name,ngram,voc, lda, X_train, X_val)\n",
        "\n",
        "      precission, recall, f1, f1_macro = createAndEvaluateModel(X_train_list, X_val_list, Y_train, Y_val, voc)\n",
        "      precissions.append(precission)\n",
        "      recalls.append(recall)\n",
        "      f1s.append(f1)\n",
        "      f1_macros.append(f1_macro)\n",
        "      gc.collect()\n",
        "  \n",
        "  npf1_macros = list(map(lambda x: round(x, 4), f1_macros))\n",
        "\n",
        "  bestIndex = npf1_macros.index(max(npf1_macros))\n",
        "  bestVecConfig = vectoriser_config[bestIndex]\n",
        "  #print(f\"\\nBest model config:\\n{bestVecConfig[0]}:{bestVecConfig[1]}:{bestVecConfig[2]} = {max(npf1_macros)}\")\n",
        "  print(f\"\\nBest model config:\\n{bestVecConfig} = {max(npf1_macros)}\")\n",
        "  return bestVecConfig"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE96mFSP6ws0"
      },
      "source": [
        "#### Running the best vectoriser configuration\n",
        "The best vectoriser vonfiguration for the model is then run on the test dataset for evaluation purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBNYeXUiEpFE",
        "outputId": "8625d9fa-444f-4038-b95b-fb92f309c01b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def printLatexOutput(output:numpy.ndarray, Y_test_int:numpy.ndarray, name:str, ngram, voc:int):\n",
        "  \"\"\"\n",
        "  This function creates a latex formated output to show the f1, precision, recall performances.\n",
        "\n",
        "    Args:\n",
        "        output (numpy.ndarray): The output of the classifier.\n",
        "        Y_test_int (numpy.ndarray): The integer values of the gold labels\n",
        "        name (str): The name of the vectorisation strategie.\n",
        "        ngram (tuple): The ngram.\n",
        "        voc (int): The vocabulary size.\n",
        "\n",
        "    Returns:\n",
        "        A latex formated output\n",
        "    \"\"\"\n",
        "  output = list(map(numpy.argmax, output))\n",
        "  precission, recall, f1, f1_macro = eval_model(output, Y_test_int)\n",
        "  labels = numpy.array(['unrelated', 'duplicate', '<=>', '<=', '=>'])\n",
        "  rearrange = numpy.array([4,3,2,0,1])\n",
        "  labels = labels[rearrange]\n",
        "  precission = numpy.array(precission)[rearrange]\n",
        "  recall = numpy.array(recall)[rearrange]\n",
        "  f1 = numpy.array(f1)[rearrange]\n",
        "\n",
        "  ng = \"\" if ngram[1] == 1 else \"_{,Un+Bigram}\"\n",
        "  output = f\"{name}_{{{voc}}}{ng}\" + \"\\t\\t\"\n",
        "  for j in range(len(labels)):\n",
        "    output += f\"& {precission[j]} & {recall[j]} \"\n",
        "  print(output + \"\\\\\\\\\")\n",
        "  output = f\"{name}_{{{voc}}}{ng}\" + \"\\t\\t\"\n",
        "\n",
        "  print(\"\\nf1 scores\\t\\t\"+ \"\\t\".join(labels) + \"\\tmacro f1\")\n",
        "  for j in range(len(labels)):\n",
        "    output += f\"& {f1[j]} \"\n",
        "  output += f\" & {f1_macro}\"\n",
        "  print(output + \"\\\\\\\\\")\n",
        "\n",
        "def vectoriseDataReturnVectoriser(name:str, ngram, voc:int, lda:bool):\n",
        "  \"\"\"\n",
        "  This function loads the training data and returns it in additino to the vectoriser and a LDA if present.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the vectorisation strategie.\n",
        "        ngram (tuple): The ngram.\n",
        "        voc (int): The vocabulary size.\n",
        "        lda (bool): Whether or not a LDA model was used.\n",
        "\n",
        "    Returns:\n",
        "        The trainings and validation data in addition to an vectoriser, and LDA\n",
        "    \"\"\"\n",
        "\n",
        "  X_train, X_val = loadTrainAndValFeatures(\"nameTrainDataset\", \"nameValDataset\")\n",
        "  Y_train, Y_val = loadTrainAndValResults(\"nameTrainDataset\", \"nameValDataset\")\n",
        "\n",
        "  vectoriser = getVectoriser(trainingsData=X_train, vocab=voc, kind=name, ngram_range=ngram)\n",
        "  X_train_list, X_val_list = vectoriseData(vectoriser, X_train, X_val, kind=name)\n",
        "  newLda = None\n",
        "  if lda:\n",
        "    newLda = GenerateLdaTopics()\n",
        "    newLda.fit(X_train.flatten())\n",
        "    tl = newLda.predict(X_train[:,0])\n",
        "    tr = newLda.predict(X_train[:,1])\n",
        "    vl = newLda.predict(X_val[:,0])\n",
        "    vr = newLda.predict(X_val[:,1])\n",
        "\n",
        "    X_train_list.append(tl)\n",
        "    X_train_list.append(tr)\n",
        "    X_val_list.append(vl)\n",
        "    X_val_list.append(vr)\n",
        "  return X_train_list, X_val_list, vectoriser, newLda\n",
        "\n",
        "def loadAndVectoriseTestData(name:str, vectoriser, lda:bool, newLda):\n",
        "  \"\"\"\n",
        "  This function cloads the test data and vectorises it using a given vectoriser.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the vectorisation strategie.\n",
        "        vectoriser (any): The vectoriser.\n",
        "        newLda (any): The LDA model or None.\n",
        "        lda (bool): Whether or not a LDA model was used.\n",
        "\n",
        "    Returns:\n",
        "        The vectorised data\n",
        "    \"\"\"\n",
        "  x_test:numpy.ndarray = loadCSVData(\"X_test\") \n",
        "  y_test:numpy.ndarray = loadNpData(\"y_test\")\n",
        "\n",
        "  X_test: List[numpy.ndarray] = batchVectorisation(x_test, vectoriser, name)#[test_dev[:,0],test_dev[:,1]]### list of numpy.ndarray[str]#\n",
        "  if lda:\n",
        "    tsl = newLda.predict(x_test[:,0])\n",
        "    tsr = newLda.predict(x_test[:,1])\n",
        "    X_test.append(tsl)\n",
        "    X_test.append(tsr)\n",
        "\n",
        "  Y_test_int:numpy.ndarray = numpy.array([numpy.argmax(numpy.array(tmp)) for tmp in y_test])\n",
        "  return X_test, Y_test_int\n",
        "\n",
        "def createBestModel(name:str,ngram,voc:int, lda:bool):\n",
        "  \"\"\"\n",
        "  This function creates the 'best' model, using the data provided.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the vectorisation strategie.\n",
        "        ngram (tuple): The ngram.\n",
        "        voc (int): The vocabulary size.\n",
        "        lda (bool): Whether or not a LDA model was used.\n",
        "\n",
        "    Returns:\n",
        "        The 'best' model itself\n",
        "  \"\"\"\n",
        "  X_train_list, X_val_list, vectoriser, newLda = vectoriseDataReturnVectoriser(name, ngram, voc, lda)\n",
        "  Y_train, Y_val = loadTrainAndValResults(\"nameTrainDataset\", \"nameValDataset\")\n",
        "  model = createModel(voc)\n",
        "  model.fit(x=X_train_list, y=Y_train, batch_size = 25, epochs=25, validation_data=(X_val_list, Y_val))\n",
        "\n",
        "  #del X_train, X_val, Y_train, Y_val\n",
        "  gc.collect()\n",
        "\n",
        "  X_test, Y_test_int = loadAndVectoriseTestData(name, vectoriser, lda, newLda)\n",
        "\n",
        "  output = model.predict(X_test, batch_size=15)\n",
        "  #print(numpy.array([f\"{rnd(x)} {numpy.argmax(x)}\" for x in output]))\n",
        "  printLatexOutput(output, Y_test_int, name, ngram, voc)\n",
        "  return model\n",
        " \n",
        "\n",
        "def rnd(num:float)->float:\n",
        "  \"\"\"\n",
        "  This function rounds the number given.\n",
        "\n",
        "    Args:\n",
        "        num (float): The number itself.\n",
        "\n",
        "    Returns:\n",
        "        The rounded number\n",
        "    \"\"\"\n",
        "  return list(map(lambda x: round(x, 4), num))\n",
        "\n",
        "vectoriser_config = [(\"count\", (1,1), 512), (\"tfIdf\", (1,1), 512), (\"count\", (1,2), 512), (\"tfIdf\", (1,2), 512), \n",
        "                     (\"count\", (1,1), 1024), (\"tfIdf\", (1,1), 1024), (\"count\", (1,2), 1024), (\"tfIdf\", (1,2), 1024),\n",
        "                     (\"count\", (1,1), 8192), (\"tfIdf\", (1,1), 8192), (\"count\", (1,2), 8192), (\"tfIdf\", (1,2), 8192),\n",
        "                     (\"count\", (1,1), 16384), (\"tfIdf\", (1,1), 16384), (\"count\", (1,2), 16384), (\"tfIdf\", (1,2), 16384),\n",
        "                     (\"sentence\",(1,1), 512)\n",
        "                     ]\n",
        "\n",
        "data_config = [\"ft_avg\", \"glove_avg\", \"ft_usif\", \"glove_usif\"]\n",
        "\n",
        "name,ngram,voc = trainAndEvaluateModel(False, vectoriser_config, False)\n",
        "model = createBestModel(name,ngram,voc, False)\n",
        "#trainAndEvaluateModel(True, data_config, False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 512)\n",
            "INFO:root:(250, 512) todo (940,)\n",
            "INFO:root:(500, 512) todo (690,)\n",
            "INFO:root:(750, 512) todo (440,)\n",
            "INFO:root:(1000, 512) todo (190,)\n",
            "INFO:root:(1190, 512) todo (0,)\n",
            "INFO:root:(250, 512) todo (420,)\n",
            "INFO:root:(500, 512) todo (170,)\n",
            "INFO:root:(670, 512) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 8ms/step - loss: 1.4934 - accuracy: 0.3370 - val_loss: 1.5212 - val_accuracy: 0.3164\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.3729 - accuracy: 0.4429 - val_loss: 1.5111 - val_accuracy: 0.3000\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.2984 - accuracy: 0.5059 - val_loss: 1.5030 - val_accuracy: 0.3149\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.2501 - accuracy: 0.5529 - val_loss: 1.5063 - val_accuracy: 0.3149\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.2038 - accuracy: 0.5689 - val_loss: 1.5068 - val_accuracy: 0.3224\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.1768 - accuracy: 0.5832 - val_loss: 1.5021 - val_accuracy: 0.3075\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.1350 - accuracy: 0.6244 - val_loss: 1.5110 - val_accuracy: 0.3134\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.1049 - accuracy: 0.6218 - val_loss: 1.5042 - val_accuracy: 0.3209\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0812 - accuracy: 0.6387 - val_loss: 1.5002 - val_accuracy: 0.3254\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0635 - accuracy: 0.6496 - val_loss: 1.5018 - val_accuracy: 0.3373\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0364 - accuracy: 0.6580 - val_loss: 1.5047 - val_accuracy: 0.3224\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0374 - accuracy: 0.6454 - val_loss: 1.5044 - val_accuracy: 0.3358\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0096 - accuracy: 0.6655 - val_loss: 1.5113 - val_accuracy: 0.3299\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.9944 - accuracy: 0.6807 - val_loss: 1.5099 - val_accuracy: 0.3343\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9667 - accuracy: 0.6857 - val_loss: 1.5056 - val_accuracy: 0.3403\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.9610 - accuracy: 0.6908 - val_loss: 1.5105 - val_accuracy: 0.3448\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.9457 - accuracy: 0.7000 - val_loss: 1.5082 - val_accuracy: 0.3493\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9309 - accuracy: 0.6975 - val_loss: 1.5104 - val_accuracy: 0.3433\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9272 - accuracy: 0.6941 - val_loss: 1.5084 - val_accuracy: 0.3478\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8933 - accuracy: 0.7193 - val_loss: 1.5163 - val_accuracy: 0.3463\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8909 - accuracy: 0.7353 - val_loss: 1.5165 - val_accuracy: 0.3403\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8809 - accuracy: 0.7269 - val_loss: 1.5134 - val_accuracy: 0.3418\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8650 - accuracy: 0.7412 - val_loss: 1.5178 - val_accuracy: 0.3403\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8596 - accuracy: 0.7353 - val_loss: 1.5276 - val_accuracy: 0.3313\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8566 - accuracy: 0.7345 - val_loss: 1.5265 - val_accuracy: 0.3358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 512)\n",
            "INFO:root:(250, 512) todo (940,)\n",
            "INFO:root:(500, 512) todo (690,)\n",
            "INFO:root:(750, 512) todo (440,)\n",
            "INFO:root:(1000, 512) todo (190,)\n",
            "INFO:root:(1190, 512) todo (0,)\n",
            "INFO:root:(250, 512) todo (420,)\n",
            "INFO:root:(500, 512) todo (170,)\n",
            "INFO:root:(670, 512) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 8ms/step - loss: 1.5242 - accuracy: 0.3555 - val_loss: 1.5331 - val_accuracy: 0.3090\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.3422 - accuracy: 0.5202 - val_loss: 1.5042 - val_accuracy: 0.3254\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.2366 - accuracy: 0.5697 - val_loss: 1.4844 - val_accuracy: 0.3313\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.1489 - accuracy: 0.6126 - val_loss: 1.4746 - val_accuracy: 0.3493\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.0873 - accuracy: 0.6387 - val_loss: 1.4663 - val_accuracy: 0.3448\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.0305 - accuracy: 0.6824 - val_loss: 1.4648 - val_accuracy: 0.3522\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9838 - accuracy: 0.6899 - val_loss: 1.4660 - val_accuracy: 0.3507\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.9441 - accuracy: 0.6992 - val_loss: 1.4594 - val_accuracy: 0.3552\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.9025 - accuracy: 0.7420 - val_loss: 1.4583 - val_accuracy: 0.3522\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8668 - accuracy: 0.7546 - val_loss: 1.4600 - val_accuracy: 0.3552\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8430 - accuracy: 0.7462 - val_loss: 1.4603 - val_accuracy: 0.3522\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.8106 - accuracy: 0.7765 - val_loss: 1.4615 - val_accuracy: 0.3612\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7927 - accuracy: 0.7765 - val_loss: 1.4669 - val_accuracy: 0.3493\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7689 - accuracy: 0.7916 - val_loss: 1.4628 - val_accuracy: 0.3627\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7408 - accuracy: 0.7992 - val_loss: 1.4652 - val_accuracy: 0.3463\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.7114 - accuracy: 0.8126 - val_loss: 1.4650 - val_accuracy: 0.3507\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6965 - accuracy: 0.8109 - val_loss: 1.4703 - val_accuracy: 0.3493\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.8235 - val_loss: 1.4723 - val_accuracy: 0.3493\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.8210 - val_loss: 1.4752 - val_accuracy: 0.3522\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.8252 - val_loss: 1.4775 - val_accuracy: 0.3567\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.8445 - val_loss: 1.4849 - val_accuracy: 0.3582\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.8420 - val_loss: 1.4861 - val_accuracy: 0.3627\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.8319 - val_loss: 1.4890 - val_accuracy: 0.3597\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.8479 - val_loss: 1.4960 - val_accuracy: 0.3552\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.8605 - val_loss: 1.4965 - val_accuracy: 0.3582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 512)\n",
            "INFO:root:(250, 512) todo (940,)\n",
            "INFO:root:(500, 512) todo (690,)\n",
            "INFO:root:(750, 512) todo (440,)\n",
            "INFO:root:(1000, 512) todo (190,)\n",
            "INFO:root:(1190, 512) todo (0,)\n",
            "INFO:root:(250, 512) todo (420,)\n",
            "INFO:root:(500, 512) todo (170,)\n",
            "INFO:root:(670, 512) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 8ms/step - loss: 1.4965 - accuracy: 0.3361 - val_loss: 1.5384 - val_accuracy: 0.3313\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.3753 - accuracy: 0.4546 - val_loss: 1.5300 - val_accuracy: 0.3269\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.3004 - accuracy: 0.5067 - val_loss: 1.5295 - val_accuracy: 0.3224\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.2599 - accuracy: 0.5353 - val_loss: 1.5274 - val_accuracy: 0.3000\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.2097 - accuracy: 0.5571 - val_loss: 1.5241 - val_accuracy: 0.3119\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.1829 - accuracy: 0.5832 - val_loss: 1.5203 - val_accuracy: 0.3269\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.1364 - accuracy: 0.6084 - val_loss: 1.5249 - val_accuracy: 0.3045\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.1176 - accuracy: 0.6109 - val_loss: 1.5262 - val_accuracy: 0.2985\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0906 - accuracy: 0.6269 - val_loss: 1.5257 - val_accuracy: 0.3015\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0715 - accuracy: 0.6303 - val_loss: 1.5308 - val_accuracy: 0.3075\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0547 - accuracy: 0.6437 - val_loss: 1.5379 - val_accuracy: 0.3119\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0390 - accuracy: 0.6521 - val_loss: 1.5375 - val_accuracy: 0.3149\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.0159 - accuracy: 0.6471 - val_loss: 1.5334 - val_accuracy: 0.3119\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9988 - accuracy: 0.6706 - val_loss: 1.5381 - val_accuracy: 0.3090\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9737 - accuracy: 0.6782 - val_loss: 1.5464 - val_accuracy: 0.3104\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.9637 - accuracy: 0.6782 - val_loss: 1.5405 - val_accuracy: 0.3104\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9525 - accuracy: 0.6866 - val_loss: 1.5431 - val_accuracy: 0.3179\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9263 - accuracy: 0.7084 - val_loss: 1.5442 - val_accuracy: 0.3119\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9255 - accuracy: 0.6908 - val_loss: 1.5458 - val_accuracy: 0.3164\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9131 - accuracy: 0.6908 - val_loss: 1.5522 - val_accuracy: 0.3194\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9103 - accuracy: 0.7084 - val_loss: 1.5553 - val_accuracy: 0.3194\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9031 - accuracy: 0.7000 - val_loss: 1.5533 - val_accuracy: 0.3209\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.8912 - accuracy: 0.6975 - val_loss: 1.5592 - val_accuracy: 0.3164\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8685 - accuracy: 0.7118 - val_loss: 1.5638 - val_accuracy: 0.3224\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8654 - accuracy: 0.7218 - val_loss: 1.5671 - val_accuracy: 0.3149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 512)\n",
            "INFO:root:(250, 512) todo (940,)\n",
            "INFO:root:(500, 512) todo (690,)\n",
            "INFO:root:(750, 512) todo (440,)\n",
            "INFO:root:(1000, 512) todo (190,)\n",
            "INFO:root:(1190, 512) todo (0,)\n",
            "INFO:root:(250, 512) todo (420,)\n",
            "INFO:root:(500, 512) todo (170,)\n",
            "INFO:root:(670, 512) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 7ms/step - loss: 1.5254 - accuracy: 0.3244 - val_loss: 1.5608 - val_accuracy: 0.2881\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.3489 - accuracy: 0.4866 - val_loss: 1.5325 - val_accuracy: 0.2925\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.2384 - accuracy: 0.5681 - val_loss: 1.5182 - val_accuracy: 0.3179\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.1608 - accuracy: 0.6025 - val_loss: 1.5092 - val_accuracy: 0.3090\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0893 - accuracy: 0.6521 - val_loss: 1.5030 - val_accuracy: 0.3239\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0374 - accuracy: 0.6664 - val_loss: 1.5002 - val_accuracy: 0.3239\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9886 - accuracy: 0.6908 - val_loss: 1.4961 - val_accuracy: 0.3358\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.9493 - accuracy: 0.6933 - val_loss: 1.4972 - val_accuracy: 0.3284\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.9076 - accuracy: 0.7261 - val_loss: 1.4939 - val_accuracy: 0.3299\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8770 - accuracy: 0.7361 - val_loss: 1.5000 - val_accuracy: 0.3284\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8472 - accuracy: 0.7563 - val_loss: 1.4972 - val_accuracy: 0.3284\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.8224 - accuracy: 0.7571 - val_loss: 1.4945 - val_accuracy: 0.3328\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7988 - accuracy: 0.7765 - val_loss: 1.4961 - val_accuracy: 0.3269\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7763 - accuracy: 0.7731 - val_loss: 1.4997 - val_accuracy: 0.3284\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.7857 - val_loss: 1.5047 - val_accuracy: 0.3269\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.8042 - val_loss: 1.5044 - val_accuracy: 0.3388\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 1s 17ms/step - loss: 0.7071 - accuracy: 0.7992 - val_loss: 1.5058 - val_accuracy: 0.3373\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.6860 - accuracy: 0.8151 - val_loss: 1.5129 - val_accuracy: 0.3328\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6690 - accuracy: 0.8202 - val_loss: 1.5164 - val_accuracy: 0.3254\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.8210 - val_loss: 1.5161 - val_accuracy: 0.3313\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.8269 - val_loss: 1.5217 - val_accuracy: 0.3284\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.8395 - val_loss: 1.5257 - val_accuracy: 0.3313\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.8403 - val_loss: 1.5296 - val_accuracy: 0.3328\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.8395 - val_loss: 1.5370 - val_accuracy: 0.3328\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.8504 - val_loss: 1.5370 - val_accuracy: 0.3343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 1024)\n",
            "INFO:root:(250, 1024) todo (940,)\n",
            "INFO:root:(500, 1024) todo (690,)\n",
            "INFO:root:(750, 1024) todo (440,)\n",
            "INFO:root:(1000, 1024) todo (190,)\n",
            "INFO:root:(1190, 1024) todo (0,)\n",
            "INFO:root:(250, 1024) todo (420,)\n",
            "INFO:root:(500, 1024) todo (170,)\n",
            "INFO:root:(670, 1024) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 9ms/step - loss: 1.4596 - accuracy: 0.3613 - val_loss: 1.5170 - val_accuracy: 0.3239\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 1.2872 - accuracy: 0.5202 - val_loss: 1.5116 - val_accuracy: 0.3478\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.1886 - accuracy: 0.5756 - val_loss: 1.5211 - val_accuracy: 0.3119\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.1188 - accuracy: 0.6286 - val_loss: 1.5062 - val_accuracy: 0.3373\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0618 - accuracy: 0.6597 - val_loss: 1.5010 - val_accuracy: 0.3284\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0004 - accuracy: 0.6849 - val_loss: 1.5038 - val_accuracy: 0.3299\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9711 - accuracy: 0.6933 - val_loss: 1.5032 - val_accuracy: 0.3403\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9229 - accuracy: 0.7244 - val_loss: 1.5074 - val_accuracy: 0.3343\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8940 - accuracy: 0.7412 - val_loss: 1.5065 - val_accuracy: 0.3403\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8634 - accuracy: 0.7420 - val_loss: 1.5092 - val_accuracy: 0.3224\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.8446 - accuracy: 0.7479 - val_loss: 1.5221 - val_accuracy: 0.3373\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8214 - accuracy: 0.7622 - val_loss: 1.5113 - val_accuracy: 0.3463\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7949 - accuracy: 0.7689 - val_loss: 1.5199 - val_accuracy: 0.3448\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7583 - accuracy: 0.7941 - val_loss: 1.5194 - val_accuracy: 0.3418\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.7444 - accuracy: 0.7916 - val_loss: 1.5234 - val_accuracy: 0.3478\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7152 - accuracy: 0.8076 - val_loss: 1.5277 - val_accuracy: 0.3597\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7154 - accuracy: 0.8000 - val_loss: 1.5238 - val_accuracy: 0.3448\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.8143 - val_loss: 1.5342 - val_accuracy: 0.3478\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6830 - accuracy: 0.8168 - val_loss: 1.5400 - val_accuracy: 0.3582\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6685 - accuracy: 0.8193 - val_loss: 1.5409 - val_accuracy: 0.3403\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.8370 - val_loss: 1.5409 - val_accuracy: 0.3343\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.8286 - val_loss: 1.5506 - val_accuracy: 0.3448\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.8395 - val_loss: 1.5491 - val_accuracy: 0.3552\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.8479 - val_loss: 1.5530 - val_accuracy: 0.3493\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.8563 - val_loss: 1.5599 - val_accuracy: 0.3507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 1024)\n",
            "INFO:root:(250, 1024) todo (940,)\n",
            "INFO:root:(500, 1024) todo (690,)\n",
            "INFO:root:(750, 1024) todo (440,)\n",
            "INFO:root:(1000, 1024) todo (190,)\n",
            "INFO:root:(1190, 1024) todo (0,)\n",
            "INFO:root:(250, 1024) todo (420,)\n",
            "INFO:root:(500, 1024) todo (170,)\n",
            "INFO:root:(670, 1024) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 8ms/step - loss: 1.4843 - accuracy: 0.3689 - val_loss: 1.5042 - val_accuracy: 0.3254\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.2154 - accuracy: 0.5790 - val_loss: 1.4808 - val_accuracy: 0.3493\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0803 - accuracy: 0.6454 - val_loss: 1.4668 - val_accuracy: 0.3582\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9827 - accuracy: 0.7050 - val_loss: 1.4741 - val_accuracy: 0.3687\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9012 - accuracy: 0.7294 - val_loss: 1.4574 - val_accuracy: 0.3716\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.8418 - accuracy: 0.7681 - val_loss: 1.4593 - val_accuracy: 0.3672\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.7765 - accuracy: 0.7975 - val_loss: 1.4557 - val_accuracy: 0.3597\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7310 - accuracy: 0.8176 - val_loss: 1.4529 - val_accuracy: 0.3716\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.8319 - val_loss: 1.4561 - val_accuracy: 0.3731\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6482 - accuracy: 0.8504 - val_loss: 1.4580 - val_accuracy: 0.3582\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.8471 - val_loss: 1.4538 - val_accuracy: 0.3791\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.8723 - val_loss: 1.4562 - val_accuracy: 0.3701\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.8866 - val_loss: 1.4597 - val_accuracy: 0.3776\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.8899 - val_loss: 1.4685 - val_accuracy: 0.3701\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.9000 - val_loss: 1.4723 - val_accuracy: 0.3597\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.8992 - val_loss: 1.4717 - val_accuracy: 0.3672\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.9092 - val_loss: 1.4806 - val_accuracy: 0.3657\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.9218 - val_loss: 1.4807 - val_accuracy: 0.3791\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.9168 - val_loss: 1.4908 - val_accuracy: 0.3687\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.9244 - val_loss: 1.4952 - val_accuracy: 0.3746\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.9210 - val_loss: 1.5018 - val_accuracy: 0.3761\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.9328 - val_loss: 1.4985 - val_accuracy: 0.3746\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.9387 - val_loss: 1.5120 - val_accuracy: 0.3791\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.9403 - val_loss: 1.5159 - val_accuracy: 0.3731\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.9471 - val_loss: 1.5272 - val_accuracy: 0.3746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 1024)\n",
            "INFO:root:(250, 1024) todo (940,)\n",
            "INFO:root:(500, 1024) todo (690,)\n",
            "INFO:root:(750, 1024) todo (440,)\n",
            "INFO:root:(1000, 1024) todo (190,)\n",
            "INFO:root:(1190, 1024) todo (0,)\n",
            "INFO:root:(250, 1024) todo (420,)\n",
            "INFO:root:(500, 1024) todo (170,)\n",
            "INFO:root:(670, 1024) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 8ms/step - loss: 1.4648 - accuracy: 0.3874 - val_loss: 1.5272 - val_accuracy: 0.2910\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 1.2921 - accuracy: 0.5218 - val_loss: 1.5189 - val_accuracy: 0.3015\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 1.1957 - accuracy: 0.5697 - val_loss: 1.5187 - val_accuracy: 0.2940\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 1.1229 - accuracy: 0.6235 - val_loss: 1.5236 - val_accuracy: 0.3090\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0735 - accuracy: 0.6286 - val_loss: 1.5126 - val_accuracy: 0.3194\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0230 - accuracy: 0.6681 - val_loss: 1.5132 - val_accuracy: 0.3269\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.9891 - accuracy: 0.6765 - val_loss: 1.5107 - val_accuracy: 0.3134\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.9547 - accuracy: 0.6983 - val_loss: 1.5117 - val_accuracy: 0.3284\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9261 - accuracy: 0.7151 - val_loss: 1.5246 - val_accuracy: 0.3179\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8917 - accuracy: 0.7345 - val_loss: 1.5238 - val_accuracy: 0.3299\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8702 - accuracy: 0.7387 - val_loss: 1.5292 - val_accuracy: 0.3373\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8462 - accuracy: 0.7487 - val_loss: 1.5289 - val_accuracy: 0.3269\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.8253 - accuracy: 0.7479 - val_loss: 1.5345 - val_accuracy: 0.3313\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7993 - accuracy: 0.7832 - val_loss: 1.5322 - val_accuracy: 0.3299\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7771 - accuracy: 0.7723 - val_loss: 1.5360 - val_accuracy: 0.3328\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.7620 - accuracy: 0.7924 - val_loss: 1.5468 - val_accuracy: 0.3239\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7423 - accuracy: 0.7773 - val_loss: 1.5470 - val_accuracy: 0.3328\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7147 - accuracy: 0.7983 - val_loss: 1.5483 - val_accuracy: 0.3313\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7083 - accuracy: 0.8017 - val_loss: 1.5563 - val_accuracy: 0.3313\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.8126 - val_loss: 1.5638 - val_accuracy: 0.3284\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6828 - accuracy: 0.8218 - val_loss: 1.5570 - val_accuracy: 0.3373\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.8084 - val_loss: 1.5660 - val_accuracy: 0.3403\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.8143 - val_loss: 1.5680 - val_accuracy: 0.3209\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.8176 - val_loss: 1.5916 - val_accuracy: 0.3209\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.8303 - val_loss: 1.5736 - val_accuracy: 0.3239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 1024)\n",
            "INFO:root:(250, 1024) todo (940,)\n",
            "INFO:root:(500, 1024) todo (690,)\n",
            "INFO:root:(750, 1024) todo (440,)\n",
            "INFO:root:(1000, 1024) todo (190,)\n",
            "INFO:root:(1190, 1024) todo (0,)\n",
            "INFO:root:(250, 1024) todo (420,)\n",
            "INFO:root:(500, 1024) todo (170,)\n",
            "INFO:root:(670, 1024) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 8ms/step - loss: 1.4929 - accuracy: 0.3588 - val_loss: 1.5066 - val_accuracy: 0.3149\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.2291 - accuracy: 0.5664 - val_loss: 1.4840 - val_accuracy: 0.3299\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 1.0946 - accuracy: 0.6403 - val_loss: 1.4726 - val_accuracy: 0.3343\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.9902 - accuracy: 0.6891 - val_loss: 1.4688 - val_accuracy: 0.3388\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9152 - accuracy: 0.7202 - val_loss: 1.4688 - val_accuracy: 0.3403\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8599 - accuracy: 0.7454 - val_loss: 1.4615 - val_accuracy: 0.3582\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7995 - accuracy: 0.7824 - val_loss: 1.4601 - val_accuracy: 0.3627\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.7549 - accuracy: 0.8034 - val_loss: 1.4589 - val_accuracy: 0.3567\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7168 - accuracy: 0.8218 - val_loss: 1.4607 - val_accuracy: 0.3657\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.8319 - val_loss: 1.4633 - val_accuracy: 0.3627\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.8286 - val_loss: 1.4602 - val_accuracy: 0.3687\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.8563 - val_loss: 1.4619 - val_accuracy: 0.3746\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.8731 - val_loss: 1.4726 - val_accuracy: 0.3821\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5533 - accuracy: 0.8731 - val_loss: 1.4737 - val_accuracy: 0.3910\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.8672 - val_loss: 1.4781 - val_accuracy: 0.3925\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.8958 - val_loss: 1.4800 - val_accuracy: 0.3821\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.8908 - val_loss: 1.4888 - val_accuracy: 0.3925\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.8983 - val_loss: 1.4896 - val_accuracy: 0.3821\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.9042 - val_loss: 1.4915 - val_accuracy: 0.3866\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.9134 - val_loss: 1.5019 - val_accuracy: 0.3672\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.9067 - val_loss: 1.4981 - val_accuracy: 0.3776\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.9118 - val_loss: 1.5065 - val_accuracy: 0.3791\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.9244 - val_loss: 1.5151 - val_accuracy: 0.3746\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.9328 - val_loss: 1.5188 - val_accuracy: 0.3836\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.9277 - val_loss: 1.5224 - val_accuracy: 0.3836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 8192)\n",
            "INFO:root:(250, 8192) todo (940,)\n",
            "INFO:root:(500, 8192) todo (690,)\n",
            "INFO:root:(750, 8192) todo (440,)\n",
            "INFO:root:(1000, 8192) todo (190,)\n",
            "INFO:root:(1190, 8192) todo (0,)\n",
            "INFO:root:(250, 8192) todo (420,)\n",
            "INFO:root:(500, 8192) todo (170,)\n",
            "INFO:root:(670, 8192) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 1.4507 - accuracy: 0.4479 - val_loss: 1.5276 - val_accuracy: 0.3373\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 1.0059 - accuracy: 0.7076 - val_loss: 1.5168 - val_accuracy: 0.3104\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.8360 - accuracy: 0.7916 - val_loss: 1.5168 - val_accuracy: 0.3194\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.7043 - accuracy: 0.8353 - val_loss: 1.4994 - val_accuracy: 0.3194\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6212 - accuracy: 0.8790 - val_loss: 1.5326 - val_accuracy: 0.3030\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.5439 - accuracy: 0.8916 - val_loss: 1.5445 - val_accuracy: 0.3119\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.4612 - accuracy: 0.9218 - val_loss: 1.5376 - val_accuracy: 0.3224\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.4130 - accuracy: 0.9252 - val_loss: 1.5400 - val_accuracy: 0.3224\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.3897 - accuracy: 0.9353 - val_loss: 1.5261 - val_accuracy: 0.3358\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 1s 17ms/step - loss: 0.3554 - accuracy: 0.9471 - val_loss: 1.5437 - val_accuracy: 0.3299\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.3288 - accuracy: 0.9479 - val_loss: 1.5652 - val_accuracy: 0.3149\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.3075 - accuracy: 0.9571 - val_loss: 1.5549 - val_accuracy: 0.3239\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.2696 - accuracy: 0.9731 - val_loss: 1.5581 - val_accuracy: 0.3373\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.2642 - accuracy: 0.9622 - val_loss: 1.5583 - val_accuracy: 0.3418\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.2624 - accuracy: 0.9622 - val_loss: 1.6329 - val_accuracy: 0.2985\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.2387 - accuracy: 0.9672 - val_loss: 1.5997 - val_accuracy: 0.3075\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 1s 17ms/step - loss: 0.2200 - accuracy: 0.9739 - val_loss: 1.5836 - val_accuracy: 0.3299\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.2139 - accuracy: 0.9706 - val_loss: 1.5914 - val_accuracy: 0.3373\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1925 - accuracy: 0.9790 - val_loss: 1.6122 - val_accuracy: 0.3104\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1742 - accuracy: 0.9857 - val_loss: 1.6018 - val_accuracy: 0.3269\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1650 - accuracy: 0.9815 - val_loss: 1.6151 - val_accuracy: 0.3224\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1479 - accuracy: 0.9899 - val_loss: 1.6141 - val_accuracy: 0.3433\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1454 - accuracy: 0.9866 - val_loss: 1.6259 - val_accuracy: 0.3403\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1395 - accuracy: 0.9908 - val_loss: 1.6375 - val_accuracy: 0.3299\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1369 - accuracy: 0.9866 - val_loss: 1.6262 - val_accuracy: 0.3388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 8192)\n",
            "INFO:root:(250, 8192) todo (940,)\n",
            "INFO:root:(500, 8192) todo (690,)\n",
            "INFO:root:(750, 8192) todo (440,)\n",
            "INFO:root:(1000, 8192) todo (190,)\n",
            "INFO:root:(1190, 8192) todo (0,)\n",
            "INFO:root:(250, 8192) todo (420,)\n",
            "INFO:root:(500, 8192) todo (170,)\n",
            "INFO:root:(670, 8192) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 1.4076 - accuracy: 0.4513 - val_loss: 1.4992 - val_accuracy: 0.2985\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.8825 - accuracy: 0.7563 - val_loss: 1.5127 - val_accuracy: 0.3134\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.7045 - accuracy: 0.8387 - val_loss: 1.4953 - val_accuracy: 0.3209\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.5596 - accuracy: 0.8782 - val_loss: 1.4970 - val_accuracy: 0.3254\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.4696 - accuracy: 0.9126 - val_loss: 1.4659 - val_accuracy: 0.3403\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.4096 - accuracy: 0.9286 - val_loss: 1.4873 - val_accuracy: 0.3328\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.3549 - accuracy: 0.9487 - val_loss: 1.5026 - val_accuracy: 0.3299\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.2938 - accuracy: 0.9613 - val_loss: 1.4920 - val_accuracy: 0.3358\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.2514 - accuracy: 0.9723 - val_loss: 1.4959 - val_accuracy: 0.3343\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.2240 - accuracy: 0.9723 - val_loss: 1.5054 - val_accuracy: 0.3239\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.2033 - accuracy: 0.9714 - val_loss: 1.5141 - val_accuracy: 0.3299\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.2233 - accuracy: 0.9714 - val_loss: 1.5120 - val_accuracy: 0.3418\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1703 - accuracy: 0.9790 - val_loss: 1.5278 - val_accuracy: 0.3313\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1527 - accuracy: 0.9832 - val_loss: 1.5154 - val_accuracy: 0.3373\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1402 - accuracy: 0.9849 - val_loss: 1.5310 - val_accuracy: 0.3358\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1260 - accuracy: 0.9874 - val_loss: 1.5305 - val_accuracy: 0.3373\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1138 - accuracy: 0.9941 - val_loss: 1.5376 - val_accuracy: 0.3358\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1060 - accuracy: 0.9941 - val_loss: 1.5418 - val_accuracy: 0.3343\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0921 - accuracy: 0.9975 - val_loss: 1.5349 - val_accuracy: 0.3493\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.0980 - accuracy: 0.9891 - val_loss: 1.5655 - val_accuracy: 0.3388\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0906 - accuracy: 0.9941 - val_loss: 1.5453 - val_accuracy: 0.3403\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.0791 - accuracy: 0.9958 - val_loss: 1.5610 - val_accuracy: 0.3254\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0708 - accuracy: 0.9958 - val_loss: 1.5632 - val_accuracy: 0.3343\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0657 - accuracy: 0.9992 - val_loss: 1.5719 - val_accuracy: 0.3373\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0686 - accuracy: 0.9950 - val_loss: 1.5596 - val_accuracy: 0.3448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 8192)\n",
            "INFO:root:(250, 8192) todo (940,)\n",
            "INFO:root:(500, 8192) todo (690,)\n",
            "INFO:root:(750, 8192) todo (440,)\n",
            "INFO:root:(1000, 8192) todo (190,)\n",
            "INFO:root:(1190, 8192) todo (0,)\n",
            "INFO:root:(250, 8192) todo (420,)\n",
            "INFO:root:(500, 8192) todo (170,)\n",
            "INFO:root:(670, 8192) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 1.4014 - accuracy: 0.4689 - val_loss: 1.5412 - val_accuracy: 0.2881\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.9610 - accuracy: 0.7160 - val_loss: 1.5049 - val_accuracy: 0.3418\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.7938 - accuracy: 0.7916 - val_loss: 1.5510 - val_accuracy: 0.3254\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6454 - accuracy: 0.8513 - val_loss: 1.5435 - val_accuracy: 0.3075\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.5762 - accuracy: 0.8697 - val_loss: 1.5467 - val_accuracy: 0.3463\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.5075 - accuracy: 0.8933 - val_loss: 1.5677 - val_accuracy: 0.3149\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.4955 - accuracy: 0.9017 - val_loss: 1.5310 - val_accuracy: 0.3463\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.3948 - accuracy: 0.9294 - val_loss: 1.5670 - val_accuracy: 0.3313\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.3522 - accuracy: 0.9412 - val_loss: 1.5672 - val_accuracy: 0.3597\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 1s 17ms/step - loss: 0.3442 - accuracy: 0.9412 - val_loss: 1.5808 - val_accuracy: 0.3507\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.3074 - accuracy: 0.9496 - val_loss: 1.6103 - val_accuracy: 0.3284\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.2791 - accuracy: 0.9580 - val_loss: 1.6082 - val_accuracy: 0.3478\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.2683 - accuracy: 0.9613 - val_loss: 1.5797 - val_accuracy: 0.3627\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.2398 - accuracy: 0.9706 - val_loss: 1.6150 - val_accuracy: 0.3358\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.2306 - accuracy: 0.9672 - val_loss: 1.6604 - val_accuracy: 0.3149\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.2117 - accuracy: 0.9697 - val_loss: 1.6363 - val_accuracy: 0.3239\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.1970 - accuracy: 0.9731 - val_loss: 1.6516 - val_accuracy: 0.3164\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1753 - accuracy: 0.9807 - val_loss: 1.6498 - val_accuracy: 0.3418\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 1s 17ms/step - loss: 0.1789 - accuracy: 0.9807 - val_loss: 1.6443 - val_accuracy: 0.3373\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1577 - accuracy: 0.9882 - val_loss: 1.6562 - val_accuracy: 0.3313\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1491 - accuracy: 0.9832 - val_loss: 1.6595 - val_accuracy: 0.3507\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1603 - accuracy: 0.9807 - val_loss: 1.6619 - val_accuracy: 0.3522\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1490 - accuracy: 0.9849 - val_loss: 1.6740 - val_accuracy: 0.3388\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1415 - accuracy: 0.9874 - val_loss: 1.6442 - val_accuracy: 0.3448\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1270 - accuracy: 0.9882 - val_loss: 1.7096 - val_accuracy: 0.3418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 8192)\n",
            "INFO:root:(250, 8192) todo (940,)\n",
            "INFO:root:(500, 8192) todo (690,)\n",
            "INFO:root:(750, 8192) todo (440,)\n",
            "INFO:root:(1000, 8192) todo (190,)\n",
            "INFO:root:(1190, 8192) todo (0,)\n",
            "INFO:root:(250, 8192) todo (420,)\n",
            "INFO:root:(500, 8192) todo (170,)\n",
            "INFO:root:(670, 8192) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 1.3679 - accuracy: 0.4479 - val_loss: 1.5101 - val_accuracy: 0.3388\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.8415 - accuracy: 0.7412 - val_loss: 1.5176 - val_accuracy: 0.3269\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.6768 - accuracy: 0.8210 - val_loss: 1.4970 - val_accuracy: 0.3537\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.5051 - accuracy: 0.9076 - val_loss: 1.5214 - val_accuracy: 0.3328\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.4093 - accuracy: 0.9235 - val_loss: 1.5225 - val_accuracy: 0.3478\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.3478 - accuracy: 0.9454 - val_loss: 1.5106 - val_accuracy: 0.3657\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.2924 - accuracy: 0.9571 - val_loss: 1.5242 - val_accuracy: 0.3552\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.2496 - accuracy: 0.9731 - val_loss: 1.5471 - val_accuracy: 0.3373\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.2162 - accuracy: 0.9832 - val_loss: 1.5184 - val_accuracy: 0.3642\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1990 - accuracy: 0.9748 - val_loss: 1.5344 - val_accuracy: 0.3507\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1813 - accuracy: 0.9798 - val_loss: 1.5413 - val_accuracy: 0.3627\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1632 - accuracy: 0.9807 - val_loss: 1.5647 - val_accuracy: 0.3343\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1382 - accuracy: 0.9908 - val_loss: 1.5843 - val_accuracy: 0.3388\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1285 - accuracy: 0.9891 - val_loss: 1.5863 - val_accuracy: 0.3403\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1076 - accuracy: 0.9966 - val_loss: 1.5928 - val_accuracy: 0.3433\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.1015 - accuracy: 0.9966 - val_loss: 1.5871 - val_accuracy: 0.3537\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0920 - accuracy: 0.9966 - val_loss: 1.5837 - val_accuracy: 0.3537\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0841 - accuracy: 0.9950 - val_loss: 1.6092 - val_accuracy: 0.3433\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0837 - accuracy: 0.9966 - val_loss: 1.5874 - val_accuracy: 0.3507\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 1s 16ms/step - loss: 0.0767 - accuracy: 0.9941 - val_loss: 1.5992 - val_accuracy: 0.3537\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0695 - accuracy: 0.9983 - val_loss: 1.6236 - val_accuracy: 0.3448\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0640 - accuracy: 0.9983 - val_loss: 1.6167 - val_accuracy: 0.3597\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0587 - accuracy: 0.9992 - val_loss: 1.6262 - val_accuracy: 0.3493\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0614 - accuracy: 0.9958 - val_loss: 1.6221 - val_accuracy: 0.3522\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.0557 - accuracy: 0.9975 - val_loss: 1.6121 - val_accuracy: 0.3687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 16384)\n",
            "INFO:root:(250, 16384) todo (940,)\n",
            "INFO:root:(500, 16384) todo (690,)\n",
            "INFO:root:(750, 16384) todo (440,)\n",
            "INFO:root:(1000, 16384) todo (190,)\n",
            "INFO:root:(1190, 16384) todo (0,)\n",
            "INFO:root:(250, 16384) todo (420,)\n",
            "INFO:root:(500, 16384) todo (170,)\n",
            "INFO:root:(670, 16384) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 2s 29ms/step - loss: 1.5239 - accuracy: 0.4319 - val_loss: 1.5274 - val_accuracy: 0.2716\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.9546 - accuracy: 0.7429 - val_loss: 1.5485 - val_accuracy: 0.2716\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.8321 - accuracy: 0.8193 - val_loss: 1.5301 - val_accuracy: 0.3030\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.6308 - accuracy: 0.8630 - val_loss: 1.5239 - val_accuracy: 0.3015\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.5359 - accuracy: 0.8882 - val_loss: 1.5735 - val_accuracy: 0.2806\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.4811 - accuracy: 0.9008 - val_loss: 1.5787 - val_accuracy: 0.2701\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.4169 - accuracy: 0.9252 - val_loss: 1.5483 - val_accuracy: 0.2851\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 1s 25ms/step - loss: 0.3760 - accuracy: 0.9244 - val_loss: 1.5393 - val_accuracy: 0.3015\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 1s 25ms/step - loss: 0.3289 - accuracy: 0.9437 - val_loss: 1.5628 - val_accuracy: 0.3090\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2953 - accuracy: 0.9546 - val_loss: 1.6098 - val_accuracy: 0.2791\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2541 - accuracy: 0.9630 - val_loss: 1.5834 - val_accuracy: 0.3060\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2369 - accuracy: 0.9672 - val_loss: 1.6135 - val_accuracy: 0.2985\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2196 - accuracy: 0.9756 - val_loss: 1.5837 - val_accuracy: 0.2851\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2025 - accuracy: 0.9731 - val_loss: 1.6650 - val_accuracy: 0.2836\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1955 - accuracy: 0.9706 - val_loss: 1.6027 - val_accuracy: 0.3045\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2132 - accuracy: 0.9782 - val_loss: 1.6032 - val_accuracy: 0.3060\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1600 - accuracy: 0.9824 - val_loss: 1.6209 - val_accuracy: 0.3149\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1467 - accuracy: 0.9824 - val_loss: 1.6329 - val_accuracy: 0.2940\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1315 - accuracy: 0.9874 - val_loss: 1.7108 - val_accuracy: 0.2731\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1259 - accuracy: 0.9899 - val_loss: 1.6297 - val_accuracy: 0.3164\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1132 - accuracy: 0.9916 - val_loss: 1.6762 - val_accuracy: 0.3045\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1085 - accuracy: 0.9891 - val_loss: 1.6255 - val_accuracy: 0.3269\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1161 - accuracy: 0.9857 - val_loss: 1.6436 - val_accuracy: 0.3060\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1094 - accuracy: 0.9908 - val_loss: 1.7040 - val_accuracy: 0.2881\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1078 - accuracy: 0.9874 - val_loss: 1.6768 - val_accuracy: 0.2985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 16384)\n",
            "INFO:root:(250, 16384) todo (940,)\n",
            "INFO:root:(500, 16384) todo (690,)\n",
            "INFO:root:(750, 16384) todo (440,)\n",
            "INFO:root:(1000, 16384) todo (190,)\n",
            "INFO:root:(1190, 16384) todo (0,)\n",
            "INFO:root:(250, 16384) todo (420,)\n",
            "INFO:root:(500, 16384) todo (170,)\n",
            "INFO:root:(670, 16384) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 2s 25ms/step - loss: 1.4740 - accuracy: 0.4529 - val_loss: 1.4929 - val_accuracy: 0.3104\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.8634 - accuracy: 0.7723 - val_loss: 1.4714 - val_accuracy: 0.3448\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.6992 - accuracy: 0.8403 - val_loss: 1.4881 - val_accuracy: 0.3313\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.5187 - accuracy: 0.8975 - val_loss: 1.5018 - val_accuracy: 0.3313\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.4273 - accuracy: 0.9176 - val_loss: 1.4981 - val_accuracy: 0.3358\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.3323 - accuracy: 0.9437 - val_loss: 1.4938 - val_accuracy: 0.3448\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.3041 - accuracy: 0.9538 - val_loss: 1.5039 - val_accuracy: 0.3463\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.2537 - accuracy: 0.9613 - val_loss: 1.5045 - val_accuracy: 0.3403\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.2253 - accuracy: 0.9647 - val_loss: 1.5224 - val_accuracy: 0.3373\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.2099 - accuracy: 0.9723 - val_loss: 1.5236 - val_accuracy: 0.3403\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.1809 - accuracy: 0.9782 - val_loss: 1.5421 - val_accuracy: 0.3418\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.1489 - accuracy: 0.9866 - val_loss: 1.5283 - val_accuracy: 0.3478\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.1396 - accuracy: 0.9899 - val_loss: 1.5359 - val_accuracy: 0.3433\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.1414 - accuracy: 0.9849 - val_loss: 1.5619 - val_accuracy: 0.3254\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.1131 - accuracy: 0.9908 - val_loss: 1.5623 - val_accuracy: 0.3254\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0895 - accuracy: 0.9933 - val_loss: 1.5694 - val_accuracy: 0.3373\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.0866 - accuracy: 0.9933 - val_loss: 1.5642 - val_accuracy: 0.3299\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0859 - accuracy: 0.9941 - val_loss: 1.5631 - val_accuracy: 0.3328\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0774 - accuracy: 0.9899 - val_loss: 1.5826 - val_accuracy: 0.3343\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0698 - accuracy: 0.9933 - val_loss: 1.5937 - val_accuracy: 0.3284\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.0626 - accuracy: 0.9958 - val_loss: 1.5671 - val_accuracy: 0.3552\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.0608 - accuracy: 0.9924 - val_loss: 1.5997 - val_accuracy: 0.3299\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0586 - accuracy: 0.9950 - val_loss: 1.5914 - val_accuracy: 0.3418\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0489 - accuracy: 0.9975 - val_loss: 1.5874 - val_accuracy: 0.3388\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0473 - accuracy: 0.9983 - val_loss: 1.6021 - val_accuracy: 0.3388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 16384)\n",
            "INFO:root:(250, 16384) todo (940,)\n",
            "INFO:root:(500, 16384) todo (690,)\n",
            "INFO:root:(750, 16384) todo (440,)\n",
            "INFO:root:(1000, 16384) todo (190,)\n",
            "INFO:root:(1190, 16384) todo (0,)\n",
            "INFO:root:(250, 16384) todo (420,)\n",
            "INFO:root:(500, 16384) todo (170,)\n",
            "INFO:root:(670, 16384) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 2s 28ms/step - loss: 1.4518 - accuracy: 0.4588 - val_loss: 1.5365 - val_accuracy: 0.2896\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.9737 - accuracy: 0.7613 - val_loss: 1.5262 - val_accuracy: 0.3299\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.8021 - accuracy: 0.8143 - val_loss: 1.6245 - val_accuracy: 0.2925\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.6646 - accuracy: 0.8672 - val_loss: 1.5575 - val_accuracy: 0.3254\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.5093 - accuracy: 0.9008 - val_loss: 1.5703 - val_accuracy: 0.3358\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.4564 - accuracy: 0.9176 - val_loss: 1.5816 - val_accuracy: 0.3045\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 1s 25ms/step - loss: 0.3764 - accuracy: 0.9370 - val_loss: 1.5754 - val_accuracy: 0.3179\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.3662 - accuracy: 0.9437 - val_loss: 1.6349 - val_accuracy: 0.2881\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.3320 - accuracy: 0.9479 - val_loss: 1.5588 - val_accuracy: 0.3328\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2827 - accuracy: 0.9529 - val_loss: 1.6513 - val_accuracy: 0.2896\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2382 - accuracy: 0.9647 - val_loss: 1.5747 - val_accuracy: 0.3522\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 1s 25ms/step - loss: 0.2081 - accuracy: 0.9655 - val_loss: 1.5993 - val_accuracy: 0.3433\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2156 - accuracy: 0.9706 - val_loss: 1.6248 - val_accuracy: 0.3373\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1735 - accuracy: 0.9798 - val_loss: 1.6325 - val_accuracy: 0.3164\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1662 - accuracy: 0.9773 - val_loss: 1.6925 - val_accuracy: 0.3149\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2074 - accuracy: 0.9697 - val_loss: 1.6719 - val_accuracy: 0.3194\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1626 - accuracy: 0.9723 - val_loss: 1.6643 - val_accuracy: 0.2955\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 1s 25ms/step - loss: 0.1197 - accuracy: 0.9857 - val_loss: 1.6733 - val_accuracy: 0.3254\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 1s 25ms/step - loss: 0.1127 - accuracy: 0.9849 - val_loss: 1.6743 - val_accuracy: 0.3254\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1131 - accuracy: 0.9849 - val_loss: 1.6612 - val_accuracy: 0.3254\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1274 - accuracy: 0.9807 - val_loss: 1.6950 - val_accuracy: 0.3134\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1050 - accuracy: 0.9832 - val_loss: 1.7587 - val_accuracy: 0.3000\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1128 - accuracy: 0.9840 - val_loss: 1.6817 - val_accuracy: 0.3209\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1058 - accuracy: 0.9874 - val_loss: 1.7166 - val_accuracy: 0.3164\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.0996 - accuracy: 0.9857 - val_loss: 1.7006 - val_accuracy: 0.3433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(2380, 16384)\n",
            "INFO:root:(250, 16384) todo (940,)\n",
            "INFO:root:(500, 16384) todo (690,)\n",
            "INFO:root:(750, 16384) todo (440,)\n",
            "INFO:root:(1000, 16384) todo (190,)\n",
            "INFO:root:(1190, 16384) todo (0,)\n",
            "INFO:root:(250, 16384) todo (420,)\n",
            "INFO:root:(500, 16384) todo (170,)\n",
            "INFO:root:(670, 16384) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 2s 25ms/step - loss: 1.4227 - accuracy: 0.4597 - val_loss: 1.5044 - val_accuracy: 0.3209\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.7804 - accuracy: 0.7832 - val_loss: 1.5133 - val_accuracy: 0.3149\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.5513 - accuracy: 0.8782 - val_loss: 1.5518 - val_accuracy: 0.2925\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.4752 - accuracy: 0.9059 - val_loss: 1.5345 - val_accuracy: 0.3149\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.3521 - accuracy: 0.9345 - val_loss: 1.5028 - val_accuracy: 0.3627\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.3074 - accuracy: 0.9580 - val_loss: 1.5584 - val_accuracy: 0.3149\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.2578 - accuracy: 0.9597 - val_loss: 1.5433 - val_accuracy: 0.3388\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.2080 - accuracy: 0.9655 - val_loss: 1.5210 - val_accuracy: 0.3672\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.2091 - accuracy: 0.9731 - val_loss: 1.5418 - val_accuracy: 0.3463\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.1385 - accuracy: 0.9824 - val_loss: 1.5536 - val_accuracy: 0.3463\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.1559 - accuracy: 0.9815 - val_loss: 1.5830 - val_accuracy: 0.3433\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.1096 - accuracy: 0.9882 - val_loss: 1.5669 - val_accuracy: 0.3493\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0989 - accuracy: 0.9899 - val_loss: 1.6014 - val_accuracy: 0.3403\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.1097 - accuracy: 0.9899 - val_loss: 1.5906 - val_accuracy: 0.3388\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.1119 - accuracy: 0.9916 - val_loss: 1.6180 - val_accuracy: 0.3463\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.0772 - accuracy: 0.9891 - val_loss: 1.6030 - val_accuracy: 0.3507\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0784 - accuracy: 0.9916 - val_loss: 1.5988 - val_accuracy: 0.3522\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.0919 - accuracy: 0.9882 - val_loss: 1.6050 - val_accuracy: 0.3597\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0616 - accuracy: 0.9933 - val_loss: 1.6253 - val_accuracy: 0.3507\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0588 - accuracy: 0.9958 - val_loss: 1.6264 - val_accuracy: 0.3373\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0476 - accuracy: 0.9958 - val_loss: 1.6235 - val_accuracy: 0.3478\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0529 - accuracy: 0.9924 - val_loss: 1.6373 - val_accuracy: 0.3373\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.0569 - accuracy: 0.9899 - val_loss: 1.6102 - val_accuracy: 0.3507\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.0428 - accuracy: 0.9958 - val_loss: 1.6246 - val_accuracy: 0.3478\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.0362 - accuracy: 0.9958 - val_loss: 1.6482 - val_accuracy: 0.3493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(250, 512) todo (940,)\n",
            "INFO:root:(500, 512) todo (690,)\n",
            "INFO:root:(750, 512) todo (440,)\n",
            "INFO:root:(1000, 512) todo (190,)\n",
            "INFO:root:(1190, 512) todo (0,)\n",
            "INFO:root:(250, 512) todo (420,)\n",
            "INFO:root:(500, 512) todo (170,)\n",
            "INFO:root:(670, 512) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 7ms/step - loss: 1.5101 - accuracy: 0.3723 - val_loss: 1.5219 - val_accuracy: 0.3478\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.3270 - accuracy: 0.5176 - val_loss: 1.4889 - val_accuracy: 0.3433\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.2100 - accuracy: 0.5798 - val_loss: 1.4768 - val_accuracy: 0.3224\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.1289 - accuracy: 0.6109 - val_loss: 1.4671 - val_accuracy: 0.3358\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.0723 - accuracy: 0.6286 - val_loss: 1.4531 - val_accuracy: 0.3463\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0196 - accuracy: 0.6513 - val_loss: 1.4488 - val_accuracy: 0.3716\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9707 - accuracy: 0.6706 - val_loss: 1.4350 - val_accuracy: 0.3716\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9329 - accuracy: 0.6866 - val_loss: 1.4357 - val_accuracy: 0.3627\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.8998 - accuracy: 0.6933 - val_loss: 1.4356 - val_accuracy: 0.3672\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8678 - accuracy: 0.7118 - val_loss: 1.4295 - val_accuracy: 0.3627\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8381 - accuracy: 0.7252 - val_loss: 1.4233 - val_accuracy: 0.3746\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.8178 - accuracy: 0.7269 - val_loss: 1.4247 - val_accuracy: 0.3866\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.7919 - accuracy: 0.7420 - val_loss: 1.4384 - val_accuracy: 0.3701\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7738 - accuracy: 0.7496 - val_loss: 1.4341 - val_accuracy: 0.3716\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.7513 - val_loss: 1.4360 - val_accuracy: 0.3881\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7655 - val_loss: 1.4313 - val_accuracy: 0.3955\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.7756 - val_loss: 1.4353 - val_accuracy: 0.4045\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.7815 - val_loss: 1.4391 - val_accuracy: 0.3896\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.7992 - val_loss: 1.4446 - val_accuracy: 0.3821\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7933 - val_loss: 1.4489 - val_accuracy: 0.3836\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.7958 - val_loss: 1.4537 - val_accuracy: 0.3866\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.8042 - val_loss: 1.4515 - val_accuracy: 0.3866\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.8076 - val_loss: 1.4569 - val_accuracy: 0.3851\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.8126 - val_loss: 1.4583 - val_accuracy: 0.3970\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.8218 - val_loss: 1.4593 - val_accuracy: 0.3896\n",
            "\n",
            "Best model config:\n",
            "('sentence', (1, 1), 512) = 0.4011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(250, 512) todo (940,)\n",
            "INFO:root:(500, 512) todo (690,)\n",
            "INFO:root:(750, 512) todo (440,)\n",
            "INFO:root:(1000, 512) todo (190,)\n",
            "INFO:root:(1190, 512) todo (0,)\n",
            "INFO:root:(250, 512) todo (420,)\n",
            "INFO:root:(500, 512) todo (170,)\n",
            "INFO:root:(670, 512) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 1s 7ms/step - loss: 1.5120 - accuracy: 0.3403 - val_loss: 1.5267 - val_accuracy: 0.3209\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.3174 - accuracy: 0.5345 - val_loss: 1.4941 - val_accuracy: 0.3254\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.2047 - accuracy: 0.5824 - val_loss: 1.4643 - val_accuracy: 0.3448\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.1243 - accuracy: 0.6168 - val_loss: 1.4533 - val_accuracy: 0.3343\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0594 - accuracy: 0.6429 - val_loss: 1.4534 - val_accuracy: 0.3239\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 1.0116 - accuracy: 0.6445 - val_loss: 1.4425 - val_accuracy: 0.3403\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.9667 - accuracy: 0.6739 - val_loss: 1.4470 - val_accuracy: 0.3239\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.9260 - accuracy: 0.6756 - val_loss: 1.4311 - val_accuracy: 0.3507\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8986 - accuracy: 0.6891 - val_loss: 1.4323 - val_accuracy: 0.3552\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.8667 - accuracy: 0.7000 - val_loss: 1.4274 - val_accuracy: 0.3552\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.8386 - accuracy: 0.7092 - val_loss: 1.4274 - val_accuracy: 0.3701\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.8186 - accuracy: 0.7176 - val_loss: 1.4406 - val_accuracy: 0.3687\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7897 - accuracy: 0.7387 - val_loss: 1.4336 - val_accuracy: 0.3701\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7708 - accuracy: 0.7462 - val_loss: 1.4358 - val_accuracy: 0.3761\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7522 - accuracy: 0.7563 - val_loss: 1.4448 - val_accuracy: 0.3791\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.7315 - accuracy: 0.7664 - val_loss: 1.4342 - val_accuracy: 0.3821\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.7154 - accuracy: 0.7697 - val_loss: 1.4391 - val_accuracy: 0.3821\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6993 - accuracy: 0.7807 - val_loss: 1.4498 - val_accuracy: 0.3806\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.7899 - val_loss: 1.4535 - val_accuracy: 0.3836\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7874 - val_loss: 1.4599 - val_accuracy: 0.3806\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.8042 - val_loss: 1.4620 - val_accuracy: 0.3806\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.7992 - val_loss: 1.4727 - val_accuracy: 0.3776\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.8000 - val_loss: 1.4610 - val_accuracy: 0.3806\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.8025 - val_loss: 1.4683 - val_accuracy: 0.3910\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.8143 - val_loss: 1.4742 - val_accuracy: 0.3881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:(250, 512) todo (630,)\n",
            "INFO:root:(500, 512) todo (380,)\n",
            "INFO:root:(750, 512) todo (130,)\n",
            "INFO:root:(880, 512) todo (0,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_{512}\t\t& 0.5 & 0.517 & 0.5246 & 0.5455 & 0.2481 & 0.1875 & 0.75 & 0.6307 & 0.2949 & 0.392 \\\\\n",
            "\n",
            "f1 scores\t\t=>\t<=\t<=>\tunrelated\tduplicate\tmacro f1\n",
            "sentence_{512}\t\t& 0.5084 & 0.5348 & 0.2136 & 0.6852 & 0.3366  & 0.4557\\\\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOvImfVokuca",
        "outputId": "5487740f-2e7f-4956-e0ea-30a00ed44013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=\"Embed_baseline.png\",\n",
        "    show_shapes=True,\n",
        "    show_dtype=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}