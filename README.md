# Issue Relations
## Introduction
When developing microservice in large, a bug/issue occurring in one component might affect another component (a so called cross-component issue).
This might not be a problem for small software architectures, but when developing software in large, this poses a serious threat due to the developers not knowing every bug of every component.

## Problem Statement
Because of this threat, a automatic issue-relation classifier is needed, to automatically predict, which issues are dependent on other issues.

## Our Solution
First we identified five kinds of issue relations:
* _issue A leads to issue B_ (henceforth =>)
* _issue B leads to issue A_ (henceforth <=)
* _issue A and B are duplicates_ (henceforth dup.)
* _issue A and B are related but the direction is unknown_ (henceforth <=>)
* _issue A and B are unrelated_ 

And for those relations we provide a microservice based solution, which automatically creates a issue relation graph for the given issues.

## How We Addressed the Issue
### Annotators
First we had to extract issue relations by manually going through [repositories](./scraped_files/allRepos.txt) and finding mentions between issues.
Secondly a participant read over the issues and added the relation of the issues if (there was one) into a text file using the URL of both issues and their relation "symbol" (=>, <=>, ...).
Unrelated issues were not collected in this step, because they were generated later on.
After one participant finished the relations [data participant A](./issue_relations/data_participant_A.txt), a second participant filled out the blanks [data Participant B](./issue_relations/data_participant_B.txt), which were handed to him instead of the relation between the URLs.\
The inter rater agreement measured using the kohens kappa between both annotators was **[TODO]** for the first **[TODO]** issues.

### Scraper
The issue data (head, body, url) as well as the comments (body, date) were scraped from the repositories using the [scraping tool](./scraping_tool/).
In addition to that, the date of the relation was also collected to enable a matching of which comments were earlier and which later.

### Creating Issue Relations
Both, the issues and their relation were then transformed into tuples *(IssueA, issueB, relation)* (the relation is a vector of the class and the issues themselves consist out of a concatenation of the issue title, body and the comments leading up to the date of the mention).\
Also, the unrelated issues were generated by creating the issue graph (unconnected a graph consisting out of smaller connected "sub" graphs) and pairing issues from different "sub" graphs together.\
Image of a connected sub-graph:
![image text](./relation_map/issue_map_cropped.png)
This ensures, that there is no transitive relation between the issues.
> A transitive relation can be seen in the picture above (the three green nodes at the top connected by "dupl." edges).
> lets call them A,B,C\
> now A is a duplicate of B, and B is a duplicate of C\
> Then A and C are probably also duplicates of each other, even though there is no edge between them.

### Relation Classifier
The classifier itself consists out of two parts, a vectoriser, which encodes the document in form of a vector and the classifier itself, for which we created a siamese like neuronal network.\

#### Vectoriser
For the vectoriser we tested several bag of words configurations like different vocabulary sizes, un- and bigrams as well as tf-idf weighting.\
In addition to that we tested fast text, and GloVe as word-level embeddings, combined using averaging them and usif as a weighted sentence/document representation.
Further, we used/tested the document embeddings obtained using the universal sentence encoder.

#### Classifier
For the classifier we created a siamese network, which takes in two inputs and creates an outputs the issue relation class.\
In order to evaluate the performance and what model works, we tested and evaluated several models.\
Using the Keras tuner to retrieve deep neuronal networks out of the models, did not lead to a improvement.

## Microservice **[todo]**
The microservice consists out of a [vectorsation service](./microservice/vectoriser/) and a [classification service](./microservice/classifier/).\
Both communicate over the following REST requests in a custom bridge network:\
http://localhost:5000/vectorise_issues
{"issueTexts": ["huehu", "aber ich bin ein doc", "anderes Document"]}

http://localhost:5000/vectorise_and_classify_issues
{"issueTexts": ["huehu", "aber ich bin ein doc", "anderes Document"]}

http://localhost:5001/classify_documents


The vectoriser uses the public available universal sentence encoder to create document embeddings, because it achieved the best results in combined with our _UniCosConcat_ classifier.

## Instructions

### instructions for the microservice



## Directory Structure


| Folder                                       | Explanation                                                                                       |
| :------------------------------------------- | :------------------------------------------------------------------------------------------------ |
| ISSUE_RELATIONS                              | This is the main folder                                                                           |
|├── [calculate_kappa](./calculate_kappa)         | Here lies the Kappa script to document the Kohens Kappa between the annotators                    |
|├── [classifier](./classifier)                   | This folder contains the code to generate the classifiers                                         |
|├── [classifier_results](./classifier_results)   | This folder contains the results of the classifiers                                               |
|├── [generate_data](./generate_data)             | Here lies the logic to generate issue relations from the scraped data                             |
|├── [graph_plotting](./graph_plotting)           | This folder contains the script for plotting issue relation graphs                                |
|├── [issue_relations](./issue_relations)         | This folder contains the data gathered by the participants                                        |
|├┬─ [microservice](./microservice)               | Here lies the microservice                                                                        |
|│└─ [classifier](./microservice/classifier)      | Here lies the classification service of the microservice                                          |
|│└─ [vectoriser](./microservice/vectoriser)      | Here lies the vectoriser service of the microservice                                              |
|├── [new_data_relation](./new_data_relation)     | This folder contains the training, and testing data as well as statistics                         |
|├── [relation_map](./relation_map)               | This folder contains images of the issue relation map                                             |
|├── [scraped_files](./scraped_files)             | Here the issues & relation gathered are lying                                                     |
|├── [scraping_tool](./scraping_tool)             | This folder contains the tool to scrape the github issues                                         |
|└── [train_and_test_data](./train_and_test_data) | This folder contains the training, validation and test data as well as statistics regarding those |
